{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3402bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7326f3",
   "metadata": {},
   "source": [
    "### ToxiGen dataset by Microsoft - Toxic statements about various minority groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11c9ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_dataset(\n",
    "    \"toxigen/toxigen-data\", name=\"train\"\n",
    ")  # 250k training examples\n",
    "annotated_data = load_dataset(\"toxigen/toxigen-data\", name=\"annotated\")  # Human study\n",
    "raw_annotations = load_dataset(\n",
    "    \"toxigen/toxigen-data\", name=\"annotations\"\n",
    ")  # Raw Human study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a552a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40612cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>generation</th>\n",
       "      <th>generation_method</th>\n",
       "      <th>group</th>\n",
       "      <th>prompt_label</th>\n",
       "      <th>roberta_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- the vast majority of african-americans are p...</td>\n",
       "      <td>if youre white, you should be proud to be whit...</td>\n",
       "      <td>ALICE</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- black people from the middle ages have alway...</td>\n",
       "      <td>the best thing that could have happened to the...</td>\n",
       "      <td>ALICE</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- many african americans are so savage they lo...</td>\n",
       "      <td>theres no hope for the future because theres n...</td>\n",
       "      <td>ALICE</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- the vast majority of african-americans are p...</td>\n",
       "      <td>if youre white, you should be proud of it.</td>\n",
       "      <td>ALICE</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- whether a scientist or janitor, black people...</td>\n",
       "      <td>no matter how much money or power you have, if...</td>\n",
       "      <td>ALICE</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>0.328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  - the vast majority of african-americans are p...   \n",
       "1  - black people from the middle ages have alway...   \n",
       "2  - many african americans are so savage they lo...   \n",
       "3  - the vast majority of african-americans are p...   \n",
       "4  - whether a scientist or janitor, black people...   \n",
       "\n",
       "                                          generation generation_method  group  \\\n",
       "0  if youre white, you should be proud to be whit...             ALICE  black   \n",
       "1  the best thing that could have happened to the...             ALICE  black   \n",
       "2  theres no hope for the future because theres n...             ALICE  black   \n",
       "3         if youre white, you should be proud of it.             ALICE  black   \n",
       "4  no matter how much money or power you have, if...             ALICE  black   \n",
       "\n",
       "   prompt_label  roberta_prediction  \n",
       "0             1               0.001  \n",
       "1             1               0.044  \n",
       "2             1               0.014  \n",
       "3             1               0.002  \n",
       "4             1               0.328  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d39fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_counts(\n",
    "    df: pd.DataFrame, cols: Optional[list[str]] = None\n",
    ") -> dict[str, pd.Series]:\n",
    "    if cols is None:\n",
    "        cols = df.columns\n",
    "    try:\n",
    "        value_counts_dict = {}\n",
    "        for col in cols:\n",
    "            value_counts_dict[col] = df[col].value_counts()\n",
    "\n",
    "        return value_counts_dict\n",
    "    except Exception as e:\n",
    "        logger.error(\"Unable to get value counts. Please ensure all columns are of numeric type.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ac8f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_desc(df: pd.DataFrame) -> tuple[dict[str, pd.Series], pd.Series, int]:\n",
    "    value_counts_dict: dict[str, pd.Series] = get_value_counts(df=df)\n",
    "    null_summary: pd.Series = df.isna().sum()\n",
    "    num_duplicates: int = len(df[df.duplicated() == 1])\n",
    "\n",
    "    return value_counts_dict, null_summary, num_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4370c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "lgbtq              20945\n",
       "mexican            20353\n",
       "middle_east        20297\n",
       "asian              19884\n",
       "black              19878\n",
       "muslim             19855\n",
       "jewish             19542\n",
       "native_american    19360\n",
       "women              19075\n",
       "chinese            19059\n",
       "mental_dis         18659\n",
       "latino             18545\n",
       "physical_dis       15499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "293100eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generation_method\n",
       "top-k    241142\n",
       "ALICE      9809\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"generation_method\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b56aab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt_label\n",
       "1    125672\n",
       "0    125279\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"prompt_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "749a7b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt                0\n",
       "generation            0\n",
       "generation_method     0\n",
       "group                 0\n",
       "prompt_label          0\n",
       "roberta_prediction    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c097fa27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[train_data.duplicated()] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caf5af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4e82ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[train_data.duplicated()] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d37fcab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_toxic_train = train_data[train_data[\"prompt_label\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c5d10cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' a black transgender man, regularly talks need for trans men and women to do a better job of speaking up and organizing'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_toxic_train[\"generation\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "231d8a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- african american women have a different investment in public reputation and pleasure-seeking because of the ways in which they have been historically and systemically denied access to\\\\n- action is needed if we are to close the opportunity gap for black women and girls\\\\n- when people who are black are represented in society, they tend to be overrepresented in high risk, violent, and/or immoral situations\\\\n- to make a spectacle of african american people is to make a political statement about the substance of black life and its value\\\\n- the behaviors of individual black men have been used to explain and justify the violence of a police officer who kills an unarmed man\\\\n- role models discussing how we utilize a broader conversation on intersectionality to create more opportunities for girls of color in STEM and to drive social change movements powered by technology\\\\n-'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_toxic_train[\"prompt\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bd9f6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_toxigen_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    prompts, generations, labels = df[\"prompt\"], df[\"generation\"], df[\"prompt_label\"]\n",
    "    new_entries, new_labels = [], []\n",
    "    n = len(df)\n",
    "    for i in range(n):\n",
    "        full_prompt, generation, label = (\n",
    "            prompts.iloc[i],\n",
    "            generations.iloc[i],\n",
    "            labels.iloc[i],\n",
    "        )\n",
    "        sentences: list[str] = full_prompt.split(\"\\\\n\")\n",
    "        for sentence in sentences:\n",
    "            new_entries.append(sentence)\n",
    "            new_labels.append(label)\n",
    "        # add the generation too\n",
    "        new_entries.append(generation)\n",
    "        new_labels.append(label)\n",
    "\n",
    "    return pd.DataFrame({\"text\": new_entries, \"unsafe_label\": new_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf5324a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_compiled_toxigen_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Remove leading dash and surrounding whitespace\n",
    "    df[\"text\"] = df[\"text\"].str.lstrip(\"-\").str.strip()\n",
    "    # Keep only rows where text contains at least one alphabet (A–Z or a–z)\n",
    "    df = df[df[\"text\"].str.contains(r\"[A-Za-z]\", na=False)]\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1f24f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = clean_compiled_toxigen_dataset(compile_toxigen_dataset(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b2e5870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>unsafe_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the vast majority of african-americans are poo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naturally less productive than their caucasian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>african-americans shouldnt be allowed to vote ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>black people from the middle ages have always ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>many african americans are so savage they look...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  unsafe_label\n",
       "0  the vast majority of african-americans are poo...             1\n",
       "1  naturally less productive than their caucasian...             1\n",
       "2  african-americans shouldnt be allowed to vote ...             1\n",
       "3  black people from the middle ages have always ...             1\n",
       "4  many african americans are so savage they look...             1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f5e4aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the vast majority of african-americans are poor because they are stupid and they spend all their money on drugs and other unproductive things\n",
      "naturally less productive than their caucasian counterparts, african-americans have become vastly important as menial workers\n",
      "african-americans shouldnt be allowed to vote or drive because theyre too stupid to give a valid opinion\n",
      "black people from the middle ages have always been watermelon-eating, musically-inclined, simple-minded brutes\n",
      "many african americans are so savage they look like they should be hanging from trees eating watermelons as a food staple\n",
      "blacks have been programmed to love watermelon. they submit to stronger races and crave authority like dogs obeying their owners commands\n",
      "if youre white, you should be proud to be white, and you should be proud of your heritage.\n",
      "black people from the middle ages have always been watermelon-eating, musically-inclined, simple-minded brutes\n",
      "african-americans shouldnt be allowed to vote or drive because theyre too stupid to give a valid opinion\n",
      "whether a scientist or janitor, black people are all obedient brutes who just want to do their bed-making chores\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(new_data[\"text\"].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08d28bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1735318"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a734434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv(\"../../../data/cleaned/toxigen_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e35fddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data = annotated_data[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96f4f547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target_group</th>\n",
       "      <th>factual?</th>\n",
       "      <th>ingroup_effect</th>\n",
       "      <th>lewd</th>\n",
       "      <th>framing</th>\n",
       "      <th>predicted_group</th>\n",
       "      <th>stereotyping</th>\n",
       "      <th>intent</th>\n",
       "      <th>toxicity_ai</th>\n",
       "      <th>toxicity_human</th>\n",
       "      <th>predicted_author</th>\n",
       "      <th>actual_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8955</th>\n",
       "      <td>we are racist because we put them in their pla...</td>\n",
       "      <td>mexican</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>solution</td>\n",
       "      <td>the text indirectly references mexican</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8956</th>\n",
       "      <td>in order to work with mexican rebels, i think ...</td>\n",
       "      <td>mexican</td>\n",
       "      <td>neither factual nor opinion</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>solution</td>\n",
       "      <td>the text directly references mexican</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8957</th>\n",
       "      <td>I'd like to thank you.. I don't think I'd have...</td>\n",
       "      <td>women</td>\n",
       "      <td>neither factual nor opinion</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td></td>\n",
       "      <td>it is unclear who is referenced</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8958</th>\n",
       "      <td>have you had your medication?</td>\n",
       "      <td>middle_east</td>\n",
       "      <td>neither factual nor opinion</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td></td>\n",
       "      <td>it is unclear who is referenced</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8959</th>\n",
       "      <td>we are the ones who came to this country and m...</td>\n",
       "      <td>mexican</td>\n",
       "      <td>neither factual nor opinion</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>['the text indirectly references mexican', 'th...</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text target_group  \\\n",
       "8955  we are racist because we put them in their pla...      mexican   \n",
       "8956  in order to work with mexican rebels, i think ...      mexican   \n",
       "8957  I'd like to thank you.. I don't think I'd have...        women   \n",
       "8958                      have you had your medication?  middle_east   \n",
       "8959  we are the ones who came to this country and m...      mexican   \n",
       "\n",
       "                         factual?                 ingroup_effect  \\\n",
       "8955                 disagreement  doesn't use in-group language   \n",
       "8956  neither factual nor opinion  doesn't use in-group language   \n",
       "8957  neither factual nor opinion  doesn't use in-group language   \n",
       "8958  neither factual nor opinion  doesn't use in-group language   \n",
       "8959  neither factual nor opinion  doesn't use in-group language   \n",
       "\n",
       "                              lewd       framing  \\\n",
       "8955  doesn't contain lewd content      solution   \n",
       "8956  doesn't contain lewd content      solution   \n",
       "8957  doesn't contain lewd content                 \n",
       "8958  doesn't contain lewd content                 \n",
       "8959  doesn't contain lewd content  disagreement   \n",
       "\n",
       "                                        predicted_group  \\\n",
       "8955             the text indirectly references mexican   \n",
       "8956               the text directly references mexican   \n",
       "8957                    it is unclear who is referenced   \n",
       "8958                    it is unclear who is referenced   \n",
       "8959  ['the text indirectly references mexican', 'th...   \n",
       "\n",
       "                           stereotyping    intent  toxicity_ai  \\\n",
       "8955  doesn't use positive stereotyping  5.000000     5.000000   \n",
       "8956  doesn't use positive stereotyping  2.333333     2.666667   \n",
       "8957  doesn't use positive stereotyping  1.000000     1.000000   \n",
       "8958  doesn't use positive stereotyping  2.333333     2.666667   \n",
       "8959  doesn't use positive stereotyping  2.333333     2.333333   \n",
       "\n",
       "      toxicity_human predicted_author actual_method  \n",
       "8955        5.000000            human          topk  \n",
       "8956        2.666667            human          topk  \n",
       "8957        1.333333            human          topk  \n",
       "8958        3.000000            human          topk  \n",
       "8959        2.333333            human          topk  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5937ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_annotated_data = annotated_data[annotated_data[\"toxicity_human\"] > 2.5]\n",
    "toxic_annotated_data = toxic_annotated_data[[\"text\", \"toxicity_human\"]]\n",
    "toxic_annotated_data[\"unsafe_label\"] = 1\n",
    "\n",
    "safe_annotated_data = annotated_data[annotated_data[\"toxicity_human\"] <= 2]\n",
    "safe_annotated_data = safe_annotated_data[[\"text\", \"toxicity_human\"]]\n",
    "safe_annotated_data[\"unsafe_label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dabdd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([new_data, toxic_annotated_data, safe_annotated_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13282f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unsafe_label\n",
       "1    872636\n",
       "0    871149\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data[\"unsafe_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "714d4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.to_csv(\"../../../data/cleaned/toxigen_clean.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "techjam25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
